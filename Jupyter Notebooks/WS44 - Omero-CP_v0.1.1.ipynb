{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f17dc8",
   "metadata": {},
   "source": [
    "# WS44 - High throughput & automated data analysis and data management workflow with Cellprofiler and OMERO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dd6e2",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this workshop we will use this Jupyter Notebook to load image data from OMERO, feed them into a Cellprofiler pipeline and automatically upload the resulting images and measurements. The uploaded data will also be annotated using tags and key:value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29faab5e",
   "metadata": {},
   "source": [
    "### Tasks during the workshop\n",
    "1.     (Data import to OMERO and preparation for analysis.)\n",
    "2.  \tAutomated data download/injection into analysis pipeline\n",
    "3.  \tAutomated data analysis using image analysis pipelines (e.g., Cellprofiler)\n",
    "4.  \tUpload of the resulting images (including tags and metadata) and measurement results (omero.tables)\n",
    "5.  \tExplorative data analysis using omero.parade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001887d7",
   "metadata": {},
   "source": [
    "### Aims of this workshop:\n",
    "\n",
    "- learn to analyze provided example datasets\n",
    "- execute the full workflow\n",
    "- perform easy adjustments of the pipeline \n",
    "- generation of new projects/datasets\n",
    "- key:value pair annotation\n",
    "- file tagging\n",
    "- explorative data analysis using omero.parade/omero.parade-crossfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9366b",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The data used in this workshop is derived from Pascual-Vargas et al., Sci Data, 2017\n",
    "\"RNAi screens for Rho GTPase regulators of cell shape and YAP/TAZ localisation in triple negative breast cancer\"\n",
    "DOI: 10.1038/sdata.2017.18\n",
    "\n",
    "The data is publicly available in the Image Data Resource (idr0028)\n",
    "https://idr.openmicroscopy.org/webclient/?show=screen-1651\n",
    "\n",
    "The datasets contain RNAi screens of cancer cells that were stained with Hoechst (Nuclei), Tubulin, Actin and Yap/Taz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097b89c",
   "metadata": {},
   "source": [
    "### Licenses & Code\n",
    "\n",
    "The code presented here is partially based on the following scripts and resources:\n",
    "\n",
    "- Omero Dataset_To_Plate.py script by Will Moore, OME Team, Copyright © 2006-2014 University of Dundee. All rights reserved. Source: https://github.com/ome/omero-scripts/blob/68c7505e62115e9c086a8e5a1d3edc1d4aff35f3/omero/util_scripts/Dataset_To_Plate.py\n",
    "<br>\n",
    "\n",
    "- InjectImage module for Cellprofiler. Copyright © 2020-2021 University of Dundee. All rights reserved. Source: https://omero-guides.readthedocs.io/en/latest/cellprofiler/docs/index.html; https://github.com/ome/omero-guide-cellprofiler\n",
    "<br>\n",
    "\n",
    "- General Omero-Python API documentation, Source: https://omero-guides.readthedocs.io/en/latest/python/docs/gettingstarted.html\n",
    "<br>\n",
    "\n",
    "- Cellprofiler Python API, Copyright © 2003 - 2021 Broad Institute, Inc. All rights reserved.Source: https://github.com/CellProfiler/CellProfiler/wiki/CellProfiler-as-a-Python-package\n",
    "<br>\n",
    "\n",
    "- ezomero (https://github.com/TheJacksonLaboratory/ezomero) \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc032a45",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089142bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cellprofiler\n",
    "import cellprofiler_core.pipeline\n",
    "import cellprofiler_core.preferences\n",
    "import cellprofiler_core.utilities.java\n",
    "import cellprofiler.modules\n",
    "import cellprofiler_core.image\n",
    "import cellprofiler_core.measurement\n",
    "import cellprofiler_core.object\n",
    "import cellprofiler_core.workspace\n",
    "from cellprofiler_core.modules.injectimage import InjectImage\n",
    "\n",
    "\n",
    "#Omero\n",
    "import ezomero\n",
    "from myconfig import OMEROUSER, OMEROPASS, OMEROPORT, OMEROHOST\n",
    "from omero.model import OriginalFileI, PlateI, ScreenPlateLinkI, ScreenI, ImageAnnotationLinkI, ImageI\n",
    "from omero.rtypes import rint, rlong, rstring, robject, unwrap\n",
    "from omero.grid import DoubleColumn, ImageColumn, LongColumn, WellColumn, StringColumn, FileColumn\n",
    "from omero.constants.namespaces import NSBULKANNOTATIONS\n",
    "from omero.gateway import FileAnnotationWrapper\n",
    "\n",
    "\n",
    "#Other\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import tempfile\n",
    "import skimage\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "import glob\n",
    "import PIL\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import getpass\n",
    "\n",
    "#Own functions\n",
    "import CP_Omero_helper as cp_omero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d7717",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "In the code block below, you will add specific analysis paramters, such as the screen and plate id, you would like to image, as well as filepaths and other settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12515e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to OMERO\n",
    "#OMEROUSER = input(f\"Enter username: \\t\")\n",
    "#OMEROPASS = getpass.getpass(prompt = f\"Enter password: \\t\")\n",
    "\n",
    "\n",
    "#OMEROHOST = ''\n",
    "#OMEROPORT = \n",
    "#OMEROWEB = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf4431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Connection Check:\n",
    "conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "print(conn.isConnected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46004d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMERO IDs\n",
    "screen_id = 852 #Insert ID of dataset that you want to analyse\n",
    "plate_id =  765#Insert corresponding plate ID\n",
    "project_id = 7911 #Project ID for temp - dataset\n",
    "selected_well = \"E6\" # Insert well you want to analyse\n",
    "tag_owner_id = 2607  # To keep the omero server clean, we will all use tags from 1 tag owner. Otherwise everyone would produce their own tags.\n",
    "\n",
    "# Pipeline\n",
    "pipe_dir = r\"D:\\PROJECTS\\MiN_Data\\Workgroups\\Sarah\\Project_OMERO-CP\\Data_Dreisewerd_TestSet\\Pipeline\\General_Pipeline_v2.cppipe\" #Insert directory of pipeline including name of pipeline\n",
    "\n",
    "# Input and saving directories:\n",
    "output_dir = \"temp_dir\" \n",
    "# if you want to use a temporary directory that is automatically created use: \"output_dir = 'temp_dir'\"\n",
    "\n",
    "# Cellprofiler-settings\n",
    "# (maybe remove)\n",
    "overwrite_results = 'Yes'  # If yes, data present in the output folder will be overwritten\n",
    "output_file_format = None  # 'npy' for numpy array, 'tiff' for image (label images: 16-bit floating point), put None if you want to keep the fileformats specified in your pipeline\n",
    "plugin_directory = \"\"\n",
    "\n",
    "# Name of the new dataset to which the label images will be uploaded\n",
    "new_plate_name = \"Results_\"\n",
    "append_original_plate_name = True # False\n",
    "\n",
    "# Specify the channels that should be used for segmentation and analysis\n",
    "# Same names as in CP pipeline!\n",
    "ch1 = \"Nuclei\" #Nuclei segmentation\n",
    "ch2 = \"Actin\" #Actin (cell body) segmentation\n",
    "ch3 = \"Tubulin\"\n",
    "ch4 = \"YapTaz\" #YapTaz for analysis\n",
    "# ... expand if you have more channel .. ch5 = xx\n",
    "\n",
    "channels = [ch1, ch2, ch3, ch4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9948d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key:Value Pairs - Add the annotations you would like to pass with your analysis results\n",
    "\n",
    "# Coud be excel sheet or textfile, or written here.\n",
    "annotation_dict= {\n",
    "\"Goal & Description\" : \"We segment the cells and calculate the YAP/Taz ratio in the nuclei.\", \n",
    "\"Software\" : \"Cellprofiler\",\n",
    "\"Software Version\": \"4.2.5\",\n",
    "\"Segmentation Algorithm\": \"Cellpose\",\n",
    "\"Segmentation Algorithm Version\": \"?\",\n",
    "\"Models\": \"nuclei, cyto2\",\n",
    "\"eLabTFW\": \"https://eln.uni-muenster.de/experiments.php?mode=edit&id=71\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb2136",
   "metadata": {},
   "source": [
    "## 1. Perform Cellprofiler Analysis\n",
    "\n",
    "In this part we will obtain the image data from omero, inject it into the cellprofiler analysis pipeline and perform the image analysis. Results will be saved on disk in the specified output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acab6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be saved to: c:\\users\\min_acc1\\appdata\\local\\temp\\4\\tmptdy49_ql\n"
     ]
    }
   ],
   "source": [
    "### Prepare Cellprofiler\n",
    "\n",
    "#Set output directory\n",
    "if output_dir == \"temp_dir\":\n",
    "    temp_dir = tempfile.mkdtemp()  # Creates a temporary directory\n",
    "    temp_path = os.path.normcase(temp_dir)\n",
    "    saving_path = pathlib.Path(temp_path).absolute()\n",
    "else:\n",
    "    saving_path = pathlib.Path(output_dir).absolute()\n",
    "\n",
    "cellprofiler_core.preferences.set_default_output_directory(f\"{saving_path}\")\n",
    "print(f\"Data will be saved to: {saving_path}\")    \n",
    "\n",
    "\n",
    "# Set-Up Cellprofiler\n",
    "cellprofiler_core.preferences.set_headless() # The headless mode runs cellprofiler without use of the GUI. \n",
    "cellprofiler_core.preferences.set_plugin_directory(plugin_directory) # Sets the plugin directory that contains the cellpose module plugin\n",
    "cellprofiler_core.preferences.set_max_workers(1) # You can increase the number of workers depending on your computer/server hardware.\n",
    "\n",
    "\n",
    "#Start the Java VM\n",
    "cellprofiler_core.utilities.java.start_java()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8702a7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to load pipeline\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\WS44\\lib\\site-packages\\cellprofiler_core\\pipeline\\_pipeline.py\", line 543, in setup_modules\n",
      "    module = self.setup_module(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\WS44\\lib\\site-packages\\cellprofiler_core\\pipeline\\_pipeline.py\", line 569, in setup_module\n",
      "    module = self.instantiate_module(module_name)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\WS44\\lib\\site-packages\\cellprofiler_core\\pipeline\\_pipeline.py\", line 197, in instantiate_module\n",
      "    return instantiate_module(module_name)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\WS44\\lib\\site-packages\\cellprofiler_core\\utilities\\core\\modules\\__init__.py\", line 180, in instantiate_module\n",
      "    module = get_module_class(module_name)()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\WS44\\lib\\site-packages\\cellprofiler_core\\utilities\\core\\modules\\__init__.py\", line 175, in get_module_class\n",
      "    raise ValueError(\"Could not find the %s module\" % module_class)\n",
      "ValueError: Could not find the RunStarDist module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove module:  Images\n",
      "Remove module:  Metadata\n",
      "Remove module:  NamesAndTypes\n",
      "Remove module:  Groups\n",
      "Pipeline modules:\n",
      "1 GrayToColor\n",
      "2 RescaleIntensity\n",
      "3 RescaleIntensity\n"
     ]
    }
   ],
   "source": [
    "# Here we load the pipeline and adjust it to work with Omero. \n",
    "\n",
    "pipeline = cp_omero.load_pipeline(pipe_dir)\n",
    "pipeline = cp_omero.adjust_pipeline(pipeline, overwrite_results, output_file_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d953d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Analysis\n",
    "\n",
    "# We define a timer to track how long the analysis will take.\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "# We connect to omero and get the plate we want to analyse\n",
    "conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True) # Connection to Omero\n",
    "plate = conn.getObject(\"Plate\", plate_id) # Gets the plate you want to analyse\n",
    "\n",
    "\n",
    "# Start of the analysis\n",
    "print(f\"You are analyzing the well {selected_well}.\")\n",
    "measurements = {}\n",
    "df_features=pd.DataFrame()\n",
    "\n",
    "\n",
    "# The code will loop through each well and perform the analysis. \n",
    "wells = list(plate.listChildren())\n",
    "\n",
    "for count, well in enumerate(wells):\n",
    "    if (well.row, well.column) == (cp_omero.well_name_to_position(selected_well)):  #For workshop purposes we only select one well to analse\n",
    "        print(well.row, well.column)\n",
    "\n",
    "    # Load a single Image per Well\n",
    "        index = well.countWellSample() # Will analyse all images in the well\n",
    "        index = 1 # Will analyse 1 image in the well (omit if you want to analyse all images)\n",
    "\n",
    "        for i in range(0, index):\n",
    "            image = well.getImage(i)\n",
    "            image_id = image.getId()\n",
    "            pixels = image.getPrimaryPixels()\n",
    "            size_c = image.getSizeC()\n",
    "\n",
    "            # For each Image in OMERO, we copy pipeline, add the image_id to the Saving and Export Modules. \n",
    "            pipeline_copy = pipeline.copy()\n",
    "\n",
    "            # Find the SaveImages modules and update its settings          \n",
    "            pipeline_copy = cp_omero.update_save_images_module_setting(pipeline, image_id)       \n",
    "                            \n",
    "            # Find the ExportToSpreadsheet module and update its settings\n",
    "            pipeline_copy = cp_omero.update_export_module_setting(pipeline, image_id)\n",
    "\n",
    "            # Inject image for each channel into the pipeline.\n",
    "            for c in range(0, size_c):\n",
    "                plane = pixels.getPlane(0, c, 0)\n",
    "                image_name = image.getName()\n",
    "                image_id = image.getId()\n",
    "\n",
    "                # Name of the channel expected in the pipeline\n",
    "                if c == 0:\n",
    "                    image_name = ch1\n",
    "                if c == 1:\n",
    "                    image_name = ch2\n",
    "                if c == 2:\n",
    "                    image_name = ch3\n",
    "                if c == 3:\n",
    "                    image_name = ch4\n",
    "                inject_image_module = InjectImage(image_name, plane)\n",
    "                inject_image_module.set_module_num(1)\n",
    "                pipeline_copy.add_module(inject_image_module)\n",
    "\n",
    "            # Here we run the pipeline on our image.\n",
    "            output_measurements = pipeline_copy.run()\n",
    "\n",
    "            # Here we process the measurement results\n",
    "            measurements[image_id] = output_measurements\n",
    "            feature_meas = output_measurements.compute_aggregate_measurements(1, aggs=None)\n",
    "            df_feature = pd.DataFrame(feature_meas, index=[image_id])\n",
    "            df_features = pd.concat([df_features,df_feature])\n",
    "            print(f\"ImageID: {image_id} :  finished\")\n",
    "\n",
    "df_features[\"Image_ID\"] = df_features.index\n",
    "df_features.to_csv(os.path.join(saving_path,\"features_summary.csv\")) #Saving the results\n",
    "\n",
    "# Timer\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(f\"Pipeline finished: {len(measurements)} images analysed\")\n",
    "\n",
    "print(f\"Analysis started: {start_time}\")\n",
    "print(f\"Analysis finished: {end_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa427a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write adjusted pipeline to file. This file will be later uploaded as file attachment. \n",
    "with open(os.path.join(str(saving_path), 'Pipeline.json'), 'w') as f:\n",
    "    pipeline_dict = {\n",
    "        'modules': [\n",
    "            {\n",
    "                'module_num': i,\n",
    "                'module_name': str(x),\n",
    "                'settings': [setting.to_dict() for setting in x.settings()]\n",
    "            }\n",
    "            for i, x in enumerate(pipeline_copy.modules())\n",
    "        ]\n",
    "    }\n",
    "    json.dump(pipeline_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2abba0",
   "metadata": {},
   "source": [
    "## 2. Upload Results To Omero\n",
    "\n",
    "We will now upload the results to omero.  \n",
    "\n",
    "We will first create a new screen and plate to host the resulting images. <br>\n",
    "Then we will derive image information (parent ID and appendix) from the file name. <br>\n",
    "The images will be updated to a (temporary) dataset. <br>\n",
    "Finally, all images will be distributed on the new results plate in the corresponding wells. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 1. Creation of plate that hosts the results #############\n",
    "#conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "screen = conn.getObject(\"Screen\", screen_id)\n",
    "\n",
    "\n",
    "# Create new plate\n",
    "plate = conn.getObject(\"Plate\", plate_id)\n",
    "if append_original_plate_name:\n",
    "    plate_name = new_plate_name + plate.name\n",
    "else:\n",
    "    plate_name = new_plate_name\n",
    "    \n",
    "results_plate = PlateI()\n",
    "results_plate.name = rstring(plate_name)\n",
    "results_plate = conn.getUpdateService().saveAndReturnObject(results_plate)\n",
    "results_plate_id = results_plate.getId()\n",
    "results_dataset_id = ezomero.post_dataset(conn, \"TempData\", project_id, description=\"Temp dataset for image results\")\n",
    "results_dataset = conn.getObject(\"Dataset\", results_dataset_id)\n",
    "\n",
    "# Links new Plate with new Screen\n",
    "link = ScreenPlateLinkI()\n",
    "link.setParent(ScreenI(screen_id, False))\n",
    "link.setChild(PlateI(results_plate_id, False))\n",
    "link_update_service = conn.getUpdateService()\n",
    "link_update_service.saveObject(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2db6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 2. Prepare image information #############\n",
    "# Find image results to upload\n",
    "results = [str(f) for f in pathlib.Path(saving_path).glob(\"*\")]\n",
    "\n",
    "image_results = [x for x in results if x.endswith((\".png\", \".npy\", \".tiff\"))]\n",
    "image_result_tags = sorted(list(set([x.strip(\".png.npy.tiff\").split(\"_\")[-1] for x in image_results])), key=lambda x: x.lower())\n",
    "image_ids = sorted(list(set([x.split(\"_\")[0] for x in image_results])), key=lambda x: x.lower())\n",
    "print(\"Resulting image types:\", image_result_tags)\n",
    "print(f\"You analysed {len(image_ids)} images.\")\n",
    "\n",
    "# Result measurements\n",
    "table_results = [x for x in results if x.endswith(\".csv\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca28d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############# 3. Main Upload #############\n",
    "conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "\n",
    "# Upload all result images\n",
    "omero_images = []\n",
    "\n",
    "for img_path in pathlib.Path(saving_path).glob((f\"*{output_file_format}\")):\n",
    "    parent_id, image = cp_omero.load_result_image_from_disk(img_path)\n",
    "    image_link = \"Original Image: \" + OMEROWEB + \"?show=image-\" + parent_id\n",
    "    omero_image = cp_omero.upload_image_from_npseq(image, img_path, conn, results_dataset, image_link)\n",
    "    omero_images.append(omero_image)\n",
    "\n",
    "cp_omero.add_images_to_plate(omero_images, plate_id, results_plate_id, conn, results_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3191fa0",
   "metadata": {},
   "source": [
    "## 3. Tag Upload\n",
    "\n",
    "To aid filtering inside omero, we will add tags to the result images based on their appendix. \n",
    "First, we query omero for all existing tags. \n",
    "Then, well find the uploaded images and add their corresponding tag to them (e.g. \"NucleiSeg\" for the nuclei-segmentation images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c856647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "\n",
    "# Create dictionary to save your existing tags\n",
    "existing_tags = {}\n",
    "\n",
    "# Define your sql query, you use an sql to search for all existing tags, to prevent creation of double tags\n",
    "sql = f\"SELECT ann.id, ann.description, ann.textValue from TagAnnotation ann WHERE ann.details.owner.id = {tag_owner_id}\"\n",
    "\n",
    "for element in conn.getQueryService().projection(sql, None):    #element: list with 3 elements (ann.id, ann.description, ann.textValue)\n",
    "                                                                #element[0]: object #0 (::omero::RLong){_val = 15286} type: <class 'omero.rtypes.RLongI'>\n",
    "    tag_id, description, text = list(map(unwrap, element))\n",
    "    existing_tags[text] = tag_id\n",
    "\n",
    "print(f\"The following tags exist: {existing_tags}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "plate = conn.getObject(\"Plate\", results_plate_id)\n",
    "\n",
    "for well in plate.listChildren():\n",
    "    index = well.countWellSample()\n",
    "    for index in range(0, index):\n",
    "        tag_name = well.getImage(index).getName().split(\".\")[0].split(\"_\")[-1]\n",
    "        if tag_name in existing_tags:\n",
    "            try:\n",
    "                tag_id = existing_tags[tag_name]\n",
    "                image = conn.getObject(\"Image\", well.getImage(index).getId())\n",
    "                image.linkAnnotation(conn.getObject(\"Annotation\", tag_id))\n",
    "                print(f\"Image {image.getName()} was tagged with {tag_name}\")\n",
    "            except omero.ValidationException:\n",
    "                print(f\"Image {image.getName()} was already tagged.\")\n",
    "        else:\n",
    "            tag_ann = omero.gateway.TagAnnotationWrapper(conn)\n",
    "            tag_ann.setValue(tag_name)\n",
    "            tag_ann.setDescription(\"No description\")\n",
    "            tag_ann.save()\n",
    "            image = conn.getObject(\"Image\", well.getImage(index).getId())\n",
    "            image.linkAnnotation(tag_ann)\n",
    "            existing_tags[tag_name] = tag_ann.id\n",
    "            print(\"New tag created: \", tag_name, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ad7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add key:value pairs to your data:\n",
    "# You can create a simple annotation dictionary to add Key:Value pairs to the plate\n",
    "\n",
    "annotation_dict = {\"TiM23\": \"WS44\", \"Software\": \"Cellprofiler 4.2.5\", \"Segmentation Algorithm\": \"Cellpose\"} \n",
    "\n",
    "# Add KV pairs to the plate:\n",
    "map_ann_id = ezomero.post_map_annotation(conn, \"Plate\", results_plate_id.getValue(), annotation_dict, \"myns\")\n",
    "\n",
    "# Add KV pairs to every image in the plate:\n",
    "results_plate = conn.getObject(\"Plate\", results_plate_id)\n",
    "\n",
    "for well in results_plate.listChildren():\n",
    "    for image in well.listChildren():\n",
    "        map_ann_id = ezomero.post_map_annotation(conn, \"Image\", image.id, annotation_dict, \"myns\")\n",
    "        \n",
    "print(f\"You added the these annotations {annotation_dict} as key:value pairs to the wells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload pipeline to results plate:\n",
    "filepath_pipeline_txt = f\"{saving_path}\\Pipeline.json\"\n",
    "file_ann_id = ezomero.post_file_annotation(conn, \"Plate\", results_plate_id.getValue(), filepath_pipeline_txt, ns= \"myns\", description=\"This pipeline was used for analysis.\")\n",
    "\n",
    "print(\"You succesfully added your pipeline as file annotation to the plate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad990545",
   "metadata": {},
   "source": [
    "## 4. Upload of ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e6a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8cb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b916e1f7",
   "metadata": {},
   "source": [
    "## 5. Upload result as omero.table\n",
    "\n",
    "Finally, we will upload the measurement results as an \"omero.table\" to Omero and link it to the analysed plate. \n",
    "These measurement results can be viewed in omero.parade-crossfilter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3628fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = os.path.join(saving_path,\"features_summary.csv\")\n",
    "#df_features = pd.read_csv(filepath)\n",
    "#df_features.rename(columns={'Unnamed: 0': \"Image_ID\"}, inplace=True)\n",
    "#conn=ezomero.connect(OMEROUSER, OMEROPASS, \"\", host=OMEROHOST, port=OMEROPORT, secure=True)\n",
    "#screen = conn.getObject(\"Screen\", screen_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the columns with the correct column types for an omero.table\n",
    "cols = []\n",
    "\n",
    "for col in df_features.columns:\n",
    "    if col == \"Image_ID\":\n",
    "        cols.append(ImageColumn(col, '', df_features[col]))\n",
    "    elif df_features[col].dtype == 'int64':\n",
    "        cols.append(LongColumn(col, '', df_features[col]))\n",
    "    elif df_features[col].dtype == 'float64':\n",
    "        cols.append(DoubleColumn(col, '', df_features[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a table\n",
    "resources = conn.c.sf.sharedResources()\n",
    "repository_id = resources.repositories().descriptions[0].getId().getValue()\n",
    "table_name = plate_name +\"_CellprofilerResults\"\n",
    "table = resources.newTable(repository_id, table_name)\n",
    "table.initialize(cols)\n",
    "table.addData(cols)\n",
    "\n",
    "# Create file annotation\n",
    "orig_file = table.getOriginalFile()\n",
    "file_ann = FileAnnotationWrapper(conn)\n",
    "file_ann.setNs(NSBULKANNOTATIONS)\n",
    "file_ann._obj.file = OriginalFileI(orig_file.id.val, False)\n",
    "file_ann.save()\n",
    "\n",
    "# Link the table to the original screen\n",
    "screen.linkAnnotation(file_ann)\n",
    "table.close()\n",
    "print(\"You added your analysis results as omero.table to your screen. You can now view them in omero.parade crossfilter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c169c",
   "metadata": {},
   "source": [
    "### 5. Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8729f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporay results data set\n",
    "conn.deleteObjects(\"Dataset\", [results_dataset_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the omero connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete your temporary directory\n",
    "if output_dir == \"temp_dir\":\n",
    "    shutil.rmtree(temp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WS44",
   "language": "python",
   "name": "ws44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
